{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4757f13-5049-4645-9216-f494202da061",
   "metadata": {},
   "source": [
    "# Training Notebook\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c8aba0-d004-417d-854d-391231f3c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefe6a3-823b-4895-8643-376dec3f5efb",
   "metadata": {},
   "source": [
    "## Resize and save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a1f46c2-1576-4bbf-b5d2-d83a3f890121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(input_path, write_path, size=(256, 256)):\n",
    "    img = cv2.imread(input_path)\n",
    "    img = cv2.resize(img, size)\n",
    "    cv2.imwrite(write_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f04a7-3a1b-4d56-be90-9e0d83995130",
   "metadata": {},
   "source": [
    "## Augmentations pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b664158-9148-4c4f-9477-c6e03bb11199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transforms = A.Compose([\n",
    "    A.Flip(p=0.5),\n",
    "    A.Rotate(limit=10, \n",
    "             border_mode=cv2.BORDER_CONSTANT, \n",
    "             value=0.0, p=0.75),\n",
    "    A.RandomResizedCrop(width=224, height=224, scale=(0.33, 1), p=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a008c6-f18e-457f-8f92-0a5e5feaf8ad",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b65d592-192a-4204-a79a-9f83a4e5c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtDataset(Dataset):\n",
    "    def __init__(self, df, label_dict, transforms=False):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.label_dict = label_dict\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Get filename and label\n",
    "        filename = ...\n",
    "        label = torch.LongTensor(self.label_dict[row['label']])\n",
    "        # Read image, correct color channels\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Augmentations\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=img.astype(np.uint8))\n",
    "            img = transformed['image']\n",
    "        # Convert to array, switch channels, scale, return\n",
    "        # img = np.transpose(img, (2, 0, 1))\n",
    "        img = torch.tensor(img / 255.).float()\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398ba02-e6e2-4994-8b0b-feef63dda6a0",
   "metadata": {},
   "source": [
    "## Transfer learning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9544e030-b2ac-4f39-8c62-688a66caea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_classification_layer(model, model_type='vgg', num_classes=25):\n",
    "    if model_type == 'vgg':\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "        )\n",
    "    elif model_type == 'resnet':\n",
    "        model.fc = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "    elif model_type == 'vit':\n",
    "        model.heads = nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "    elif model_type == 'convnext':\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.LayerNorm2d((768,), eps=1e-06, elementwise_affine=True),\n",
    "            nn.Flatten(start_dim=1, end_dim=-1),\n",
    "            nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "        )\n",
    "    else:\n",
    "        print(f'Unknown model_type {model_type}. Acceptable types are: \"vgg\", \"resnet\", \"vit\", or \"convnext\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e4e755-b8b4-4536-9fa6-b9382a7bef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model, **classargs):\n",
    "    '''\n",
    "    Given an existing model, freeze pre-trained weights and\n",
    "    re-instantiate the classifier.\n",
    "    '''\n",
    "    # Freeze all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Re-instantiate the classifier head\n",
    "    set_classification_layer(model, **classargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa7e59f1-a90f-49e5-be84-e0a0e8ca2a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight gradient is set to True\n",
      "features.0.bias gradient is set to True\n",
      "features.2.weight gradient is set to True\n",
      "features.2.bias gradient is set to True\n",
      "features.5.weight gradient is set to True\n",
      "features.5.bias gradient is set to True\n",
      "features.7.weight gradient is set to True\n",
      "features.7.bias gradient is set to True\n",
      "features.10.weight gradient is set to True\n",
      "features.10.bias gradient is set to True\n",
      "features.12.weight gradient is set to True\n",
      "features.12.bias gradient is set to True\n",
      "features.14.weight gradient is set to True\n",
      "features.14.bias gradient is set to True\n",
      "features.17.weight gradient is set to True\n",
      "features.17.bias gradient is set to True\n",
      "features.19.weight gradient is set to True\n",
      "features.19.bias gradient is set to True\n",
      "features.21.weight gradient is set to True\n",
      "features.21.bias gradient is set to True\n",
      "features.24.weight gradient is set to True\n",
      "features.24.bias gradient is set to True\n",
      "features.26.weight gradient is set to True\n",
      "features.26.bias gradient is set to True\n",
      "features.28.weight gradient is set to True\n",
      "features.28.bias gradient is set to True\n",
      "classifier.0.weight gradient is set to True\n",
      "classifier.0.bias gradient is set to True\n",
      "classifier.3.weight gradient is set to True\n",
      "classifier.3.bias gradient is set to True\n",
      "classifier.6.weight gradient is set to True\n",
      "classifier.6.bias gradient is set to True\n"
     ]
    }
   ],
   "source": [
    "vgg = models.vgg16()\n",
    "for name, param in vgg.named_parameters():\n",
    "    print(f\"{name} gradient is set to\", param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55149a7-4b1d-4341-a720-eaeed45ff2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze model\n",
    "freeze_model(vgg, num_classes=25, model_type='vgg')\n",
    "vgg.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "319b266a-c6e9-499e-abd6-04b2a6acfa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight gradient is set to False\n",
      "features.0.bias gradient is set to False\n",
      "features.2.weight gradient is set to False\n",
      "features.2.bias gradient is set to False\n",
      "features.5.weight gradient is set to False\n",
      "features.5.bias gradient is set to False\n",
      "features.7.weight gradient is set to False\n",
      "features.7.bias gradient is set to False\n",
      "features.10.weight gradient is set to False\n",
      "features.10.bias gradient is set to False\n",
      "features.12.weight gradient is set to False\n",
      "features.12.bias gradient is set to False\n",
      "features.14.weight gradient is set to False\n",
      "features.14.bias gradient is set to False\n",
      "features.17.weight gradient is set to False\n",
      "features.17.bias gradient is set to False\n",
      "features.19.weight gradient is set to False\n",
      "features.19.bias gradient is set to False\n",
      "features.21.weight gradient is set to False\n",
      "features.21.bias gradient is set to False\n",
      "features.24.weight gradient is set to False\n",
      "features.24.bias gradient is set to False\n",
      "features.26.weight gradient is set to False\n",
      "features.26.bias gradient is set to False\n",
      "features.28.weight gradient is set to False\n",
      "features.28.bias gradient is set to False\n",
      "classifier.0.weight gradient is set to True\n",
      "classifier.0.bias gradient is set to True\n",
      "classifier.3.weight gradient is set to True\n",
      "classifier.3.bias gradient is set to True\n",
      "classifier.6.weight gradient is set to True\n",
      "classifier.6.bias gradient is set to True\n"
     ]
    }
   ],
   "source": [
    "for name, param in vgg.named_parameters():\n",
    "    print(f\"{name} gradient is set to\", param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf361b-d5ce-40a9-a143-2e4aa2fb28de",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a6764-f802-46db-91f6-845fc0641ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for easily passing training arguments\n",
    "training_params = {'epochs': 10,\n",
    "                  'batch_size': 16,\n",
    "                  'loss_fct': nn.CrossEntropyLoss()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670fbaa-1108-4579-a3ef-27daf629fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dl, training_params):\n",
    "    # Get GPU if available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_obs = 0\n",
    "    total_correct = 0\n",
    "    loss_fct = training_params['loss_fct']\n",
    "    for X, y in dl:\n",
    "        n_obs = len(y)\n",
    "        # Forward pass and calculate loss\n",
    "        yhat = model(X.to(device))#.softmax(dim=1)\n",
    "        loss = loss_fct(yhat.to(device), y.to(device))\n",
    "        total_loss += n_obs * loss.item()\n",
    "        total_obs += n_obs\n",
    "        # Calculate batch accuracy\n",
    "        ypred = np.argmax(yhat.cpu().detach().numpy(), axis=1)\n",
    "        y_arr = y.detach().numpy()\n",
    "        total_correct += n_obs * accuracy_score(y_arr, ypred)\n",
    "    # Return loss, accuracy\n",
    "    avg_loss = total_loss / total_obs\n",
    "    accuracy = total_correct / total_obs\n",
    "    return avg_loss, accuracy\n",
    "    \n",
    "    \n",
    "def train_model(model, optimizer, scheduler, train_ds, valid_ds, training_params):\n",
    "    # Get loss function\n",
    "    loss_fct = training_params['loss_fct']\n",
    "    # Create dataloaders based on batch size\n",
    "    batch_size = trainin_params['batch_size']\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "    # Get GPU if available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    # Train\n",
    "    for _ in range(training_params['epochs']):\n",
    "        # Put model in train mode\n",
    "        model.train()\n",
    "        # Train on training dataloader\n",
    "        for X, y in train_dl:\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass and loss calculation\n",
    "            yhat = model(X.to(device))#.softmax(dim=1)\n",
    "            loss = loss_fct(yhat.to(device), y.to(device))\n",
    "            # Backward pass and step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        # Calculate loss, accuracy on train and validation\n",
    "        train_loss, train_acc = eval_model(model, train_dl)\n",
    "        valid_loss, valid_acc = eval_model(model, valid_dl)\n",
    "        train_str = f\"train loss: {train_loss:.4f} | train acc: {train_acc:.4f}\"\n",
    "        valid_str = f\" | valid loss: {valid_loss:.4f} | valid acc: {valid_acc:.4f}\"\n",
    "        print(f'[{_}] ' + train_str + valid_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deaea268-d422-4a86-87de-81e473aa1ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be769fa-3a30-4527-95d0-71da048a0f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
