{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a208be",
   "metadata": {},
   "source": [
    "# Training Style Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569a3b6",
   "metadata": {},
   "source": [
    "Installing all the required libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505b97af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torchsummary\n",
    "# ! pip install --upgrade opencv-python\n",
    "# ! pip install albumentations\n",
    "# ! pip install s3fs\n",
    "# ! pip install tqdm\n",
    "# ! pip install torch\n",
    "# ! pip install torchvision\n",
    "# ! conda install --yes pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch -c conda-forge\n",
    "# ! pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d8e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vambati/anaconda3/envs/deep-learning/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import skimage.io as skio\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2061e87e",
   "metadata": {},
   "source": [
    "* Reading the dataframe containing the information about the artworks. Can be found in [data/](https://github.com/avmchandrish/art-style-classification/tree/main/data) folder in the github repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b05fae1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>artistName</th>\n",
       "      <th>image</th>\n",
       "      <th>map</th>\n",
       "      <th>paintingUrl</th>\n",
       "      <th>artistUrl</th>\n",
       "      <th>albums</th>\n",
       "      <th>flags</th>\n",
       "      <th>images</th>\n",
       "      <th>style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>57728479edc2cb3880fdea33</td>\n",
       "      <td>Silhouette fantastique</td>\n",
       "      <td>1854</td>\n",
       "      <td>500</td>\n",
       "      <td>366</td>\n",
       "      <td>Victor Hugo</td>\n",
       "      <td>https://uploads0.wikiart.org/images/victor-hug...</td>\n",
       "      <td>0*23**67*</td>\n",
       "      <td>/en/victor-hugo/silhouette-fantastique-1854</td>\n",
       "      <td>/en/victor-hugo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract-art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57728a62edc2cb388010efa1</td>\n",
       "      <td>First Communion of Anaemic Young Girls in the ...</td>\n",
       "      <td>1883</td>\n",
       "      <td>1324</td>\n",
       "      <td>848</td>\n",
       "      <td>Alphonse Allais</td>\n",
       "      <td>https://uploads0.wikiart.org/images/alphonse-a...</td>\n",
       "      <td>01234*67*</td>\n",
       "      <td>/en/alphonse-allais/first-communion-of-anaemic...</td>\n",
       "      <td>/en/alphonse-allais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract-art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>57728a61edc2cb388010ef5f</td>\n",
       "      <td>Apoplectic Cardinals Harvesting Tomatoes on th...</td>\n",
       "      <td>1884</td>\n",
       "      <td>1400</td>\n",
       "      <td>980</td>\n",
       "      <td>Alphonse Allais</td>\n",
       "      <td>https://uploads2.wikiart.org/images/alphonse-a...</td>\n",
       "      <td>01234*67*</td>\n",
       "      <td>/en/alphonse-allais/apoplectic-cardinals-harve...</td>\n",
       "      <td>/en/alphonse-allais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract-art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>57728a61edc2cb388010ef71</td>\n",
       "      <td>Band of Greyfriars in the Fog (Band Of Dusty D...</td>\n",
       "      <td>1884</td>\n",
       "      <td>1400</td>\n",
       "      <td>980</td>\n",
       "      <td>Alphonse Allais</td>\n",
       "      <td>https://uploads2.wikiart.org/images/alphonse-a...</td>\n",
       "      <td>01234*67*</td>\n",
       "      <td>/en/alphonse-allais/band-of-greyfriars-in-the-...</td>\n",
       "      <td>/en/alphonse-allais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract-art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>57728a61edc2cb388010ef81</td>\n",
       "      <td>Negroes Fighting in a Tunnel by Night</td>\n",
       "      <td>1884</td>\n",
       "      <td>800</td>\n",
       "      <td>560</td>\n",
       "      <td>Alphonse Allais</td>\n",
       "      <td>https://uploads5.wikiart.org/images/alphonse-a...</td>\n",
       "      <td>0123**67*</td>\n",
       "      <td>/en/alphonse-allais/negroes-fighting-in-a-tunn...</td>\n",
       "      <td>/en/alphonse-allais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abstract-art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        id  \\\n",
       "0           0  57728479edc2cb3880fdea33   \n",
       "1           1  57728a62edc2cb388010efa1   \n",
       "2           2  57728a61edc2cb388010ef5f   \n",
       "3           3  57728a61edc2cb388010ef71   \n",
       "4           4  57728a61edc2cb388010ef81   \n",
       "\n",
       "                                               title  year  width  height  \\\n",
       "0                             Silhouette fantastique  1854    500     366   \n",
       "1  First Communion of Anaemic Young Girls in the ...  1883   1324     848   \n",
       "2  Apoplectic Cardinals Harvesting Tomatoes on th...  1884   1400     980   \n",
       "3  Band of Greyfriars in the Fog (Band Of Dusty D...  1884   1400     980   \n",
       "4              Negroes Fighting in a Tunnel by Night  1884    800     560   \n",
       "\n",
       "        artistName                                              image  \\\n",
       "0      Victor Hugo  https://uploads0.wikiart.org/images/victor-hug...   \n",
       "1  Alphonse Allais  https://uploads0.wikiart.org/images/alphonse-a...   \n",
       "2  Alphonse Allais  https://uploads2.wikiart.org/images/alphonse-a...   \n",
       "3  Alphonse Allais  https://uploads2.wikiart.org/images/alphonse-a...   \n",
       "4  Alphonse Allais  https://uploads5.wikiart.org/images/alphonse-a...   \n",
       "\n",
       "         map                                        paintingUrl  \\\n",
       "0  0*23**67*        /en/victor-hugo/silhouette-fantastique-1854   \n",
       "1  01234*67*  /en/alphonse-allais/first-communion-of-anaemic...   \n",
       "2  01234*67*  /en/alphonse-allais/apoplectic-cardinals-harve...   \n",
       "3  01234*67*  /en/alphonse-allais/band-of-greyfriars-in-the-...   \n",
       "4  0123**67*  /en/alphonse-allais/negroes-fighting-in-a-tunn...   \n",
       "\n",
       "             artistUrl  albums  flags images         style  \n",
       "0      /en/victor-hugo     NaN      2    NaN  abstract-art  \n",
       "1  /en/alphonse-allais     NaN      2    NaN  abstract-art  \n",
       "2  /en/alphonse-allais     NaN      2    NaN  abstract-art  \n",
       "3  /en/alphonse-allais     NaN      2    NaN  abstract-art  \n",
       "4  /en/alphonse-allais     NaN      2    NaN  abstract-art  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read artworks df\n",
    "artworks = pd.read_csv('data/artworks.csv')\n",
    "artworks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7807e0",
   "metadata": {},
   "source": [
    "Creating a column with file path, to access the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b91a7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a path is: abstract-art/silhouette-fantastique-1854.jpg\n"
     ]
    }
   ],
   "source": [
    "# Create col with filename\n",
    "artworks['s3_path'] = artworks.apply(lambda row: row['style'] \\\n",
    "                                     + \"/\" + row['image'].split('/')[-1].split('.')[0] + \".jpg\", \n",
    "                                     axis=1)\n",
    "print(f\"Example of a path is: {artworks['s3_path'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c49b305",
   "metadata": {},
   "source": [
    "Checking the number of images for each of the class in the data. Ut looks fairly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8fae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rococo                        3600\n",
       "neoclassicism                 3600\n",
       "symbolism                     3600\n",
       "art-nouveau-modern            3600\n",
       "baroque                       3600\n",
       "surrealism                    3600\n",
       "romanticism                   3600\n",
       "expressionism                 3600\n",
       "impressionism                 3600\n",
       "realism                       3600\n",
       "abstract-expressionism        3600\n",
       "naive-art-primitivism         3600\n",
       "post-impressionism            3540\n",
       "cubism                        3419\n",
       "northern-renaissance          3273\n",
       "pop-art                       2712\n",
       "mannerism-late-renaissance    2536\n",
       "minimalism                    2242\n",
       "abstract-art                  2040\n",
       "art-informel                  1888\n",
       "early-renaissance             1876\n",
       "ukiyo-e                       1857\n",
       "high-renaissance              1759\n",
       "magic-realism                 1758\n",
       "color-field-painting          1597\n",
       "Name: style, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artworks['style'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68f099",
   "metadata": {},
   "source": [
    "### Data Augmentations\n",
    "\n",
    "We are using Flip, Rotate and Random Crop augentations. Also we would be normalizing the images according to imagenet stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174441e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transforms = A.Compose([\n",
    "    A.Flip(p=0.5),\n",
    "    A.Rotate(limit=10, \n",
    "             border_mode=cv2.BORDER_CONSTANT, \n",
    "             value=0.0, p=0.75),\n",
    "    A.RandomResizedCrop(width=224, height=224, scale=(0.5, 1), p=1),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225), \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac3efe",
   "metadata": {},
   "source": [
    "### Dataset Class\n",
    "\n",
    "This dataset class takes as parameters:\n",
    "* Dataframe containing file locations, \n",
    "* Label dictionary with label names and their indexes\n",
    "* transforms to be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d833b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtDataset(Dataset):\n",
    "    def __init__(self, df, label_dict, transforms, fs= None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.label_dict = label_dict\n",
    "        self.fs = fs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Get filename and label\n",
    "        filename = row['s3_path']\n",
    "        #label = torch.zeros(25, dtype = torch.long)\n",
    "        label = torch.tensor(label_dict[row['style']], dtype = torch.long)\n",
    "        # Read image, correct color channels\n",
    "        img = self.load_img(filename)\n",
    "#        print(img)\n",
    "        # adding this portion if the image has 4 channels or more -- Chandrish\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis = 2)\n",
    "            img = np.repeat(img, 3, axis = 2)\n",
    "        elif img.shape[2] > 3:\n",
    "            img = img[:, :, :3]\n",
    "        # Augmentations + normalization\n",
    "        transformed = self.transforms(image=img.astype(np.uint8))\n",
    "        img = transformed['image']\n",
    "        \n",
    "        img = img.transpose(2, 0, 1)\n",
    "        # Convert to tensor\n",
    "        img = torch.tensor(img).float()\n",
    "        #img = torch.permute(2, 0, 1)\n",
    "        return img, label\n",
    "    \n",
    "    def load_img(self, s3_path):\n",
    "        try:\n",
    "            img_arr = skio.imread(s3_path)\n",
    "            img_arr.shape\n",
    "        except:\n",
    "            img_arr = skio.imread('symbolism/baroness-fernand-van-der-bruggen-1900.jpg')\n",
    "        return img_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df62007",
   "metadata": {},
   "source": [
    "### Transfer learning functions\n",
    "\n",
    "The function below reinstantiates the head of the architecture and takes paramters:\n",
    "* model: the model architecture\n",
    "* model type: 'vgg'/'resnet'/'vit'\n",
    "* num_classes: number of classes we are classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2928f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_classification_layer(model, model_type='vgg', num_classes=25):\n",
    "    if model_type == 'vgg':\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "        )\n",
    "    elif model_type == 'resnet':\n",
    "        model.fc = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "    elif model_type == 'vit':\n",
    "        model.heads = nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "    elif model_type == 'convnext':\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.LayerNorm2d((768,), eps=1e-06, elementwise_affine=True),\n",
    "            nn.Flatten(start_dim=1, end_dim=-1),\n",
    "            nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "        )\n",
    "    else:\n",
    "        print(f'Unknown model_type {model_type}. Acceptable types are: \"vgg\", \"resnet\", \"vit\", or \"convnext\"')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e41b5",
   "metadata": {},
   "source": [
    "The function below freezes all the layers of the architecture and makes the linear layers learnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e061e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model, **classargs):\n",
    "    '''\n",
    "    Given an existing model, freeze pre-trained weights and\n",
    "    re-instantiate the classifier.\n",
    "    '''\n",
    "    # Freeze all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Re-instantiate the classifier head\n",
    "    model = set_classification_layer(model, **classargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59793a76",
   "metadata": {},
   "source": [
    "Testing out the above function, by loading in a VGG 19 model and checking it's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c882d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight gradient is set to True\n",
      "features.0.bias gradient is set to True\n",
      "features.2.weight gradient is set to True\n",
      "features.2.bias gradient is set to True\n",
      "features.5.weight gradient is set to True\n",
      "features.5.bias gradient is set to True\n",
      "features.7.weight gradient is set to True\n",
      "features.7.bias gradient is set to True\n",
      "features.10.weight gradient is set to True\n",
      "features.10.bias gradient is set to True\n",
      "features.12.weight gradient is set to True\n",
      "features.12.bias gradient is set to True\n",
      "features.14.weight gradient is set to True\n",
      "features.14.bias gradient is set to True\n",
      "features.16.weight gradient is set to True\n",
      "features.16.bias gradient is set to True\n",
      "features.19.weight gradient is set to True\n",
      "features.19.bias gradient is set to True\n",
      "features.21.weight gradient is set to True\n",
      "features.21.bias gradient is set to True\n",
      "features.23.weight gradient is set to True\n",
      "features.23.bias gradient is set to True\n",
      "features.25.weight gradient is set to True\n",
      "features.25.bias gradient is set to True\n",
      "features.28.weight gradient is set to True\n",
      "features.28.bias gradient is set to True\n",
      "features.30.weight gradient is set to True\n",
      "features.30.bias gradient is set to True\n",
      "features.32.weight gradient is set to True\n",
      "features.32.bias gradient is set to True\n",
      "features.34.weight gradient is set to True\n",
      "features.34.bias gradient is set to True\n",
      "classifier.0.weight gradient is set to True\n",
      "classifier.0.bias gradient is set to True\n",
      "classifier.3.weight gradient is set to True\n",
      "classifier.3.bias gradient is set to True\n",
      "classifier.6.weight gradient is set to True\n",
      "classifier.6.bias gradient is set to True\n"
     ]
    }
   ],
   "source": [
    "# Load VGG-19\n",
    "vgg = models.vgg19()\n",
    "for name, param in vgg.named_parameters():\n",
    "    print(f\"{name} gradient is set to\", param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "966b56f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight gradient is set to False\n",
      "features.0.bias gradient is set to False\n",
      "features.2.weight gradient is set to False\n",
      "features.2.bias gradient is set to False\n",
      "features.5.weight gradient is set to False\n",
      "features.5.bias gradient is set to False\n",
      "features.7.weight gradient is set to False\n",
      "features.7.bias gradient is set to False\n",
      "features.10.weight gradient is set to False\n",
      "features.10.bias gradient is set to False\n",
      "features.12.weight gradient is set to False\n",
      "features.12.bias gradient is set to False\n",
      "features.14.weight gradient is set to False\n",
      "features.14.bias gradient is set to False\n",
      "features.16.weight gradient is set to False\n",
      "features.16.bias gradient is set to False\n",
      "features.19.weight gradient is set to False\n",
      "features.19.bias gradient is set to False\n",
      "features.21.weight gradient is set to False\n",
      "features.21.bias gradient is set to False\n",
      "features.23.weight gradient is set to False\n",
      "features.23.bias gradient is set to False\n",
      "features.25.weight gradient is set to False\n",
      "features.25.bias gradient is set to False\n",
      "features.28.weight gradient is set to False\n",
      "features.28.bias gradient is set to False\n",
      "features.30.weight gradient is set to False\n",
      "features.30.bias gradient is set to False\n",
      "features.32.weight gradient is set to False\n",
      "features.32.bias gradient is set to False\n",
      "features.34.weight gradient is set to False\n",
      "features.34.bias gradient is set to False\n",
      "classifier.0.weight gradient is set to True\n",
      "classifier.0.bias gradient is set to True\n",
      "classifier.3.weight gradient is set to True\n",
      "classifier.3.bias gradient is set to True\n",
      "classifier.6.weight gradient is set to True\n",
      "classifier.6.bias gradient is set to True\n"
     ]
    }
   ],
   "source": [
    "# Freeze model\n",
    "freeze_model(vgg, num_classes=25, model_type='vgg')\n",
    "# Check frozen layers\n",
    "for name, param in vgg.named_parameters():\n",
    "    print(f\"{name} gradient is set to\", param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60122c",
   "metadata": {},
   "source": [
    "After passing through the function all the layers except the heads have their requires grad as False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e645dd4",
   "metadata": {},
   "source": [
    "### Training functions\n",
    "\n",
    "We have two functions below\n",
    "* eval_model: To calculate the loss and accuracy with a given model and dataloader\n",
    "* train_model: To train the model based on training parameters, optimizer and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03d20f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for easily passing training arguments\n",
    "training_params = {'epochs': 20,\n",
    "                  'batch_size': 16,\n",
    "                  'loss_fct': nn.CrossEntropyLoss()}\n",
    "\n",
    "\n",
    "def eval_model(model, dl, training_params):\n",
    "    # Get GPU if available\n",
    "    device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    # model = model.to(device)\n",
    "    total_loss = 0\n",
    "    total_obs = 0\n",
    "    total_correct = 0\n",
    "    loss_fct = training_params['loss_fct']\n",
    "    for X, y in tqdm(dl):\n",
    "        n_obs = len(y)\n",
    "        # Forward pass and calculate loss\n",
    "        yhat = model(X.to(device))#.softmax(dim=1)\n",
    "        loss = loss_fct(yhat.to(device), y.to(device))\n",
    "        total_loss += n_obs * loss.item()\n",
    "        total_obs += n_obs\n",
    "        # Calculate batch accuracy\n",
    "        ypred = np.argmax(yhat.cpu().detach().numpy(), axis=1)\n",
    "        y_arr = y.detach().numpy()\n",
    "        total_correct += n_obs * accuracy_score(y_arr, ypred)\n",
    "    # Return loss, accuracy\n",
    "    avg_loss = total_loss / total_obs\n",
    "    accuracy = total_correct / total_obs\n",
    "    return avg_loss, accuracy\n",
    "    \n",
    "    \n",
    "def train_model(model, optimizer, scheduler, train_ds, valid_ds, training_params):\n",
    "    # Get loss function\n",
    "    loss_fct = training_params['loss_fct']\n",
    "    # Create dataloaders based on batch size\n",
    "    batch_size = training_params['batch_size']\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    valid_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "    # Get GPU if available\n",
    "    device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    # Train\n",
    "    for _ in range(training_params['epochs']):\n",
    "        # Put model in train mode\n",
    "        model.train()\n",
    "        # Train on training dataloader\n",
    "        for X, y in tqdm(train_dl):\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass and loss calculation\n",
    "            yhat = model(X.to(device))#.softmax(dim=1)\n",
    "            loss = loss_fct(yhat.to(device), y.to(device))\n",
    "            # Backward pass and step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()  # update scheduler each epoch\n",
    "        # Calculate loss, accuracy on train and validation\n",
    "        train_loss, train_acc = eval_model(model, train_dl, training_params)\n",
    "        valid_loss, valid_acc = eval_model(model, valid_dl, training_params)\n",
    "        train_str = f\"train loss: {train_loss:.4f} | train acc: {train_acc:.4f}\"\n",
    "        valid_str = f\" | valid loss: {valid_loss:.4f} | valid acc: {valid_acc:.4f}\"\n",
    "        print(f'[{_}] ' + train_str + valid_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff3c43",
   "metadata": {},
   "source": [
    "### Train Val Test Split\n",
    "\n",
    "We are splitting the files into:\n",
    "* Train: 70% of data (around 50K images)\n",
    "* Valid: 15% of data\n",
    "* Test: 15% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7612a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = artworks.sample(frac = 1, random_state = 62).reset_index(drop = True)\n",
    "split1 = int(0.7 * df.shape[0])\n",
    "split2 = int(0.85 * df.shape[0])\n",
    "train_df, valid_df, test_df = df.iloc[:split1].copy(), df.iloc[split1: split2].reset_index(drop = True), \\\n",
    "                                    df.iloc[split2:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a04c6",
   "metadata": {},
   "source": [
    "### Instantiate Datasets\n",
    "\n",
    "Defining the Train, Valid and Test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c37e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label dict\n",
    "label_dict = {style: i for i, style in enumerate(sorted(artworks['style'].unique()))}\n",
    "\n",
    "# creating Datasets\n",
    "train_ds = ArtDataset(train_df, label_dict, transforms)\n",
    "valid_ds = ArtDataset(train_df, label_dict, transforms)\n",
    "test_ds = ArtDataset(train_df, label_dict, transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0de33",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f722af5",
   "metadata": {},
   "source": [
    "### Training - VGG 19\n",
    "\n",
    "We are loading a pretrained VGG19 model and freezing the layer and training it. <br>\n",
    "The actual training happens using the script file which can be found [here](https://github.com/avmchandrish/art-style-classification/tree/main/scripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 19\n",
    "from torchvision.models import vgg19\n",
    "model = vgg19(pretrained = True)\n",
    "\n",
    "# freezing the parameters\n",
    "freeze_model(model, num_classes=25, model_type='vgg')\n",
    "\n",
    "# training\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "optimizer = optim.Adam(model.parameters(), )\n",
    "scheduler = StepLR(optimizer, step_size=4, gamma=0.5)\n",
    "training_params = {'epochs': 10,\n",
    "                  'batch_size': 128,\n",
    "                  'loss_fct': nn.CrossEntropyLoss()}\n",
    "train_model(model, optimizer, scheduler, train_ds, valid_ds, training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5239a6",
   "metadata": {},
   "source": [
    "### Training - ResNet 34\n",
    "\n",
    "We are loading a pretrained ResNet34 model and freezing the layer and training it. <br>\n",
    "The actual training happens using the script file which can be found [here](https://github.com/avmchandrish/art-style-classification/tree/main/scripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a544231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet 34\n",
    "from torchvision.models import resnet34\n",
    "model = resnet34(pretrained = True)\n",
    "\n",
    "# freezing the parameters\n",
    "freeze_model(model, num_classes=25, model_type='resnet')\n",
    "\n",
    "# training\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "optimizer = optim.Adam(model.parameters(), )\n",
    "scheduler = StepLR(optimizer, step_size=4, gamma=0.5)\n",
    "training_params = {'epochs': 10,\n",
    "                  'batch_size': 128,\n",
    "                  'loss_fct': nn.CrossEntropyLoss()}\n",
    "train_model(model, optimizer, scheduler, train_ds, valid_ds, training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce116234",
   "metadata": {},
   "source": [
    "### Training - ViT\n",
    "\n",
    "We are loading a pretrained Vision Transformer model and freezing the layer and training it. <br>\n",
    "The actual training happens using the script file which can be found [here](https://github.com/avmchandrish/art-style-classification/tree/main/scripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT\n",
    "from torchvision.models import vit_b_16\n",
    "model = vit_b_16(pretrained = True)\n",
    "\n",
    "# freezing the parameters\n",
    "freeze_model(model, num_classes=25, model_type='vit')\n",
    "\n",
    "# training\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "optimizer = optim.Adam(model.parameters(), )\n",
    "scheduler = StepLR(optimizer, step_size=4, gamma=0.5)\n",
    "training_params = {'epochs': 10,\n",
    "                  'batch_size': 128,\n",
    "                  'loss_fct': nn.CrossEntropyLoss()}\n",
    "train_model(model, optimizer, scheduler, train_ds, valid_ds, training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f658e4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac253714",
   "metadata": {},
   "source": [
    "### References\n",
    "* Learning rate scheduler: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html\n",
    "* Torchvision models: https://pytorch.org/vision/stable/models.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
